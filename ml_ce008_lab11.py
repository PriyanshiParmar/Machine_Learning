# -*- coding: utf-8 -*-
"""ML_CE008_Lab11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Jy6fdcpkz9Y4mIPj4y1MqzQY_NhOADp

Part A: Basic SVM with Linear Kernel
"""

import sys, os
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import metrics

# importing scikit learn with make_blobs
from sklearn.datasets import make_blobs
# creating datasets X containing n_samples
# Y containing two classes
X, Y = make_blobs(n_samples=1000, n_features=2, random_state = 86)
# plotting scatters
plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolor="k")

# Split data to train and test on 80-20 ratio

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state= 8, test_size=20)

# Create a linear SVM classifier
clf = svm.SVC(kernel='linear')

# Train classifier
clf.fit(X_train, Y_train)

## Plot decision function on training and test data
#plot_decision_function(X_train, y_train, X_test, y_test,clf)

# Make predictions on unseen test data
#clf_predictions = #############################
predictions = clf.predict(X_test)
print("Accuracy: {}%".format(	metrics.accuracy_score(Y_test, predictions) * 100))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, predictions, average = None))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, predictions, average = None))

def make_meshgrid(x, y, h=.02):
  x_min, x_max = x.min() - 1, x.max() + 1
  y_min, y_max = y.min() - 1, y.max() + 1
  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
  return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
  Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
  Z = Z.reshape(xx.shape)
  out = ax.contourf(xx, yy, Z, **params)
  return out

fig, ax = plt.subplots()
# title for the plots
title = ('Decision surface of linear SVC ')
# Set-up grid for plotting.
X0, X1 = X[:, 0], X[:, 1]
xx, yy = make_meshgrid(X0, X1)
plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X0, X1, c=Y, cmap=plt.cm.coolwarm, s=20,edgecolors='k')
ax.set_ylabel('y label here')
ax.set_xlabel('x label here')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend()
plt.show()

"""Part B : Breast Cancer Prediction Example"""

#Import scikit-learn dataset library
from sklearn import datasets
#Load dataset
cancer = datasets.load_breast_cancer()

# print the names of the 13 features
cancer.feature_names

# print the label type of cancer('malignant' 'benign')
cancer.target_names

# print data(feature)shape
cancer.data.shape

# print the cancer labels (0:malignant, 1:benign)
cancer.target

# plotting scatters
# plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolor="k")

#Import svm model
from sklearn import svm
#Create a svm Classifier
clf = svm.SVC(kernel='linear')
#Train the model using the training sets
####################
X_train, X_test, Y_train, Y_test = train_test_split(cancer.data, cancer.target, random_state = 8, test_size = 20)
clf.fit(X_train, Y_train)
#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred))

"""4 Exercise

1. Implement SVM classifier on MNIST dataset, compare the performance of linear, poly-
nomial and RBF kernels.
"""

from sklearn.datasets import fetch_openml
import pandas as pd
mnist_digits = fetch_openml('mnist_784')
# mnist_digits.head()

X = mnist_digits["data"]
Y = mnist_digits["target"]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 8, test_size = 20)

from sklearn import metrics

#linear svm
clf = svm.SVC(kernel='linear')
clf.fit(X_train, Y_train)
y_pred = clf.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred))

from sklearn import metrics

#polynomial svm
clf = svm.SVC(kernel='poly', degree=3)
clf.fit(X_train, Y_train)
y_pred = clf.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred))

from sklearn import metrics

#rbf svm
clf = svm.SVC(kernel='rbf')
clf.fit(X_train, Y_train)
y_pred = clf.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred))

"""2. What is the accuracy, precision and recall of the models generated in Part A and Part B.

Done Above

3. For Part A and Part B change the value of hyperparameter C and compare the results.

PART A
"""

import sys, os
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import metrics

# importing scikit learn with make_blobs
from sklearn.datasets import make_blobs
# creating datasets X containing n_samples
# Y containing two classes
X, Y = make_blobs(n_samples=1000, n_features=2, random_state = 86)
# plotting scatters
plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolor="k")
# Split data to train and test on 80-20 ratio

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state= 8, test_size=20)

# Create a linear SVM classifier
clfa1 = svm.SVC(kernel='linear', C= 100)

# Train classifier
clfa1.fit(X_train, Y_train)

## Plot decision function on training and test data
#plot_decision_function(X_train, y_train, X_test, y_test,clf)

# Make predictions on unseen test data
#clf_predictions = #############################
predictions = clfa1.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, predictions))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, predictions, average = None))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, predictions, average = None))

# Create a linear SVM classifier
clfa2 = svm.SVC(kernel='linear', C= 0.3)

# Train classifier
clfa2.fit(X_train, Y_train)

## Plot decision function on training and test data
#plot_decision_function(X_train, y_train, X_test, y_test,clf)

# Make predictions on unseen test data
#clf_predictions = #############################
predictions = clfa2.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, predictions))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, predictions, average = None))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, predictions, average = None))

# Create a linear SVM classifier
clfa3 = svm.SVC(kernel='linear', C= 20)

# Train classifier
clfa3.fit(X_train, Y_train)

## Plot decision function on training and test data
#plot_decision_function(X_train, y_train, X_test, y_test,clf)

# Make predictions on unseen test data
#clf_predictions = #############################
predictions = clfa3.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, predictions))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, predictions, average = None))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, predictions, average = None))

# Create a linear SVM classifier
clfa4 = svm.SVC(kernel='linear', C= 0.00070)

# Train classifier
clfa4.fit(X_train, Y_train)

## Plot decision function on training and test data
#plot_decision_function(X_train, y_train, X_test, y_test,clf)

# Make predictions on unseen test data
#clf_predictions = #############################
predictions = clfa4.predict(X_test)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, predictions))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, predictions, average = None))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, predictions, average = None))

"""PART B"""

#Import scikit-learn dataset library
from sklearn import datasets
#Import svm model
from sklearn import svm

#Load dataset
cancer = datasets.load_breast_cancer()
X_train, X_test, Y_train, Y_test = train_test_split(cancer.data, cancer.target, random_state = 8, test_size = 20)

#Create a svm Classifier
clfb1 = svm.SVC(kernel='linear', C=3)
#Train the model using the training sets
####################

clfb1.fit(X_train, Y_train)
#Predict the response for test dataset
y_pred = clfb1.predict(X_test)
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred))

#Create a svm Classifier
clfb2 = svm.SVC(kernel='linear', C=100)
#Train the model using the training sets
####################

clfb2.fit(X_train, Y_train)
#Predict the response for test dataset
y_pred = clfb2.predict(X_test)
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
# Model Precision: what percentage of positive tuples arelabeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred))
# Model Recall: what percentage of positive tuples arelabelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred))