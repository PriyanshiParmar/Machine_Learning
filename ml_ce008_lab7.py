# -*- coding: utf-8 -*-
"""ML_CE008_Lab7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G1LmJXak3ycKBFXlfKVmko3cI4nynLwy
"""

import numpy as np
import pandas as pd
import io
import matplotlib.pyplot as plt
from google.colab import files

uploaded = files.upload()
data = pd.read_csv(io.BytesIO(uploaded['BuyComputer.csv']))

# data.drop(columns=['User ID',], axis=1, inplace=True)
# print(data.head())

import numpy as np
import pandas as pd
import io
import matplotlib.pyplot as plt
from google.colab import files

data.drop(columns=['User ID',], axis=1, inplace=True)
print(data.head())

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

label = data.iloc[ : , -1].values
X = data.iloc[:,:-1].values
print(label[:5])
print(X[:5])

# Splitting data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = 0,0,0,0
# Sacaling data
X_train, X_test, y_train, y_test = train_test_split(X,label, test_size= 0.2, random_state = 8)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
# y_train

import math

def model(x_age, x_salary, theta0, theta_age, theta_salary):
  return 1/(1 + math.exp(-1 * (theta0 + theta_age*x_age + theta_salary*x_salary)))

def loss(pred_y, actual_y):
  return (actual_y) and (-1 * math.log10(pred_y)) or (-1 * math.log10(1-pred_y))

loss(model(X_train[0][0], X_train[0][1],1,1,1), y_train[0]), y_train[0], model(X_train[0][0], X_train[0][1],1,1,1)

# Update rule
def update(theta, lr, m, pred_y, actual_y, feature_i=0):
  summation = 0
  for i in range(len(pred_y)):
    summation = summation + (pred_y[i] - actual_y[i])*(feature_i and feature_i[i] or 1)
  # print("summ: ",summation)
  return theta - (lr/m)*summation

# For 1 epoch
# We have model, loss fn, and update rule
theta_0, theta_age, theta_salary = 1,1,1
epochs = 10 # 100
learning_rate = 10

X_train_df = pd.DataFrame(X_train, columns=["Age", "EstimatedSalary"])
age = X_train_df["Age"].tolist()
estimated_salary = X_train_df["EstimatedSalary"].tolist()

for j in range(epochs):
  y_train_pred = []
  m = len(X_train)
  for i in range(m):
    y_train_pred.append(model(X_train[i][0], X_train[i][1], theta_0, theta_age, theta_salary))
    loss_value = loss(y_train_pred[i], y_train[i])
  print(f"Epoch {j} Iteration {i+1}: Loss: ",loss_value)
  theta_0 = update(theta_0, learning_rate, m, y_train_pred, y_train)
  theta_age = update(theta_age, learning_rate, m, y_train_pred, y_train, age)
  theta_salary = update(theta_salary, learning_rate, m, y_train_pred, y_train, estimated_salary)
  # print("New theta values: ",theta_0, theta_age, theta_salary)

y_test_pred = []
for i in range(len(X_test)):
  if model(X_test[i][0], X_test[i][1], theta_0, theta_age, theta_salary) < 0.5:
    y_test_pred.append(0)
  else:
    y_test_pred.append(1)

accuracy = 0 # (TP + TN)/Total
precision = 0 # (TP/TP+FP)
recall = 0 # (TP/TP+FN)
# F_Score = 2PR/(P+R)
TP, FP, TN, FN = 0,0,0,0

for i in range(len(X_test)):
  if y_test_pred[i]==1 and y_test[i]==1:
    TP = TP+1
  if y_test[i]==0 and y_test_pred[i]==1:
    FP = FP+1
  if y_test_pred[i]==0 and y_test[i]==0:
    TN = TN+1
  if y_test_pred[i]==0 and y_test[i]==1:
    FN = FN+1
    
accuracy = (TP+TN)/len(X_test)
precision = TP/(TP+FP)
recall = TP/(TP+FN)
F_Score = (2*precision*recall)/(precision+recall)
print(f"Accuracy: {accuracy}\nPrecision: {precision}\nRecall: {recall}\nF Score: {F_Score}")

import matplotlib.pyplot as plt
plt.plot(epochs,loss_value)
plt.xlabel('Epoch')
plt.ylabel('Loss')
# plt.legend()
plt.show()

"""Using Built in losgistic Regression model

"""

from sklearn.linear_model import LogisticRegression
LR = LogisticRegression(random_state = 8)

LR.fit(X_train, y_train)
# print(X_test.shape)
y_pred = LR.predict(X_test)

from sklearn import metrics

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test,y_pred))
print("Recall:",metrics.recall_score(y_test,y_pred))
print("F1 score:",metrics.f1_score(y_test,y_pred))

LR.predict([[28,76000]])