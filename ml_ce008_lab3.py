# -*- coding: utf-8 -*-
"""ML_CE008_Lab3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uTRgT7uLUbANtOZr8tTK_01R30RmRLo2

1.5.1 (1) Will you play if the temperature is ‘Hot’ and weather is ‘overcast’?
"""

from sklearn import preprocessing
from sklearn.naive_bayes import GaussianNB, MultinomialNB

weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']

temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild', 'Cool','Mild','Mild','Mild','Hot','Mild']

play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes', 'Yes','Yes','Yes','Yes','No']

le = preprocessing.LabelEncoder()

weather_encoded = le.fit_transform(weather)
temp_encoded = le.fit_transform(temp)
label = le.fit_transform(play)

# print("Weather:" ,weather_encoded)
# print("Temp:",temp_encoded)
# print("Play:",label)

features = tuple(zip(temp_encoded, weather_encoded))
model = MultinomialNB()

model.fit(features,label)
predicted = model.predict([[1,0]])
print("Predicted: ", predicted)

"""1.5.2 (2) Will you play if the temperature is ‘Mild’ and weather is ‘Sunny’?"""

from sklearn import preprocessing
from sklearn.naive_bayes import GaussianNB, MultinomialNB

weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']

temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild', 'Cool','Mild','Mild','Mild','Hot','Mild']

play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes', 'Yes','Yes','Yes','Yes','No']

le = preprocessing.LabelEncoder()

weather_encoded = le.fit_transform(weather)
temp_encoded = le.fit_transform(temp)
label = le.fit_transform(play)

# print("Weather:" ,weather_encoded)
# print("Temp:",temp_encoded)
# print("Play:",label)

features = tuple(zip(temp_encoded, weather_encoded))
model = MultinomialNB()

model.fit(features,label)
predicted = model.predict([[2,2]])
print("Predicted: ", predicted)

"""2. Categorical NB

"""

from sklearn import preprocessing
from sklearn.naive_bayes import CategoricalNB

weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']

temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild', 'Cool','Mild','Mild','Mild','Hot','Mild']

play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes', 'Yes','Yes','Yes','Yes','No']

le = preprocessing.LabelEncoder()

weather_encoded = le.fit_transform(weather)
temp_encoded = le.fit_transform(temp)
label = le.fit_transform(play)

# print("Weather:" ,weather_encoded)
# print("Temp:",temp_encoded)
# print("Play:",label)

features = tuple(zip(temp_encoded, weather_encoded))
model = CategoricalNB()

model.fit(features,label)
predicted = model.predict([[2,2]])
print("Predicted: ", predicted)

from sklearn import preprocessing
from sklearn.naive_bayes import GaussianNB

weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']

temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild', 'Cool','Mild','Mild','Mild','Hot','Mild']

play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes', 'Yes','Yes','Yes','Yes','No']

le = preprocessing.LabelEncoder()

weather_encoded = le.fit_transform(weather)
temp_encoded = le.fit_transform(temp)
label = le.fit_transform(play)

# print("Weather:" ,weather_encoded)
# print("Temp:",temp_encoded)
# print("Play:",label)

features = tuple(zip(temp_encoded, weather_encoded))
model = GaussianNB()

model.fit(features,label)
predicted = model.predict([[2,2]])
print("Predicted: ", predicted)

"""3_NB_Classifier_Iris_3Classes"""

#Import scikit-learn dataset library
from sklearn import datasets
from sklearn.naive_bayes import GaussianNB
#Load dataset
iris = datasets.load_iris()

# print the names of the 13 features
print("Features: ", iris.feature_names)
# print the label type of wine(class_0, class_1, class_2)
print("Labels: ", iris.target_names)
# print data(feature)shape
iris.data.shape

#import the necessary module
from sklearn.model_selection import train_test_split
#split data set into train and test sets
data_train, data_test, target_train, target_test = train_test_split(iris.data,
iris.target, test_size = 0.30, random_state = 10)

import numpy as np
gnb = GaussianNB()
#Train the model using the training sets
gnb.fit(data_train, target_train)
#Predict the response for test dataset
target_pred = gnb.predict(data_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
from sklearn.metrics import confusion_matrix
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(target_test, target_pred))


confusion_matrix(target_test, target_pred)

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
precision = precision_score(target_test, target_pred, average=None)
recall = recall_score(target_test, target_pred, average=None)
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))

"""1) 1<=Rollnumber<=25: 

Task 1: Try the algo on Dataset1 - OneHotEncoding of features: and Train test Division 70%-30%

Task 2: Apply algorithm on digits dataset - LabelEncoding of features: and Train test Division 80%-20%

Task 1: Try the algo on Dataset1 - OneHotEncoding of features: and Train test Division 70%-30%
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.naive_bayes import CategoricalNB, MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

datasets = pd.read_csv('drive/MyDrive/Dataset1.csv')
features = datasets.iloc[:,:-1].values
label = datasets.iloc[:, -1].values

# print("Features: \n",features)
# print("Label: \n", label)

# le = LabelEncoder()
# features[:, 0] = le.fit_transform(features[:,0])
# features[:, 1] = le.fit_transform(features[:,1])
# features[:, 2] = le.fit_transform(features[:,2])
# features[:, 3] = le.fit_transform(features[:,3])
# print(features)

dummy_outlook = pd.get_dummies(datasets['Outlook'])
datasets = datasets.drop(['Outlook','Play'], axis=1)
datasets = pd.concat([dummy_outlook, datasets], axis = 1)

dummy_temp = pd.get_dummies(datasets['Temp'])
datasets = datasets.drop(['Temp'], axis=1)
datasets = pd.concat([dummy_temp, datasets], axis = 1)

dummy_hum = pd.get_dummies(datasets['Humidity'])
datasets = datasets.drop(['Humidity'], axis=1)
datasets = pd.concat([dummy_hum, datasets], axis = 1)

dummy_wind = pd.get_dummies(datasets['Wind'])
datasets = datasets.drop(['Wind'], axis=1)
datasets = pd.concat([dummy_wind, datasets], axis = 1)

print(datasets)

data_train, data_test, target_train, target_test = train_test_split(datasets, label, test_size=0.30, random_state = 8)

cb = CategoricalNB()

cb.fit(data_train, target_train)
target_pred = cb.predict(data_test)

print("Accuracy: ", metrics.accuracy_score(target_test, target_pred))

confusion_matrix(target_test, target_pred)
precision = precision_score(target_test, target_pred, average=None)
recall=recall_score(target_test, target_pred, average=None)

print('Precision: {}'.format(precision))
print('Recall: {}'.format(recall))

# print(model.predict[])

"""(1) What will be the value of Play, if Outlook is ’Rainy’, Temperature is ’Mild’, Humidity =’Nor-
mal’, and Wind = ’False’?
"""

cb.predict([[1,0,0,0,1,0,0,1,0,1,0]])

"""(2) What will be the value of Play, if Outlook is ’Sunny’, Temeprature is ’Cool’, Humidity =’High’,
and Wind = ’True’?
"""

cb.predict([[1,0,1,0,0,1,0,0,0,0,1]])

from google.colab import drive
drive.mount('/content/drive')

"""Task 2: Apply algorithm on digits dataset - LabelEncoding of features: and Train test Division 80%-20%"""

from sklearn.datasets import load_digits
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.naive_bayes import CategoricalNB, MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

digits = load_digits()
features = digits.data
label = digits.target

# print(digits.data)
le = LabelEncoder()
for i in range(64):
    features[:, i] = le.fit_transform(features[:,i]);

# features = le.fit_transform(digits.feature_names)
# features[:, 1] = le.fit_transform(features[:,1])
# features[:, 2] = le.fit_transform(features[:,2])
# features[:, 3] = le.fit_transform(features[:,3])
print("Features: \n",features)
print("Label: \n", label)
# print(features.shape)
# print(digits.feature_names)

datasets = np.concatenate((features, label[:, None]), axis = 1)
print(datasets)
data_train, data_test, target_train, target_test = train_test_split(datasets, label, test_size=0.20, random_state = 8)

cb = MultinomialNB()

cb.fit(data_train, target_train)


# print("Train data\n", data_train, data_train.shape)
# print("Train target\n", target_train, target_train.shape)
# print("Test data \n", data_test, data_test.shape)
# print("Test target\n", target_test, target_test.shape)
target_pred = cb.predict(data_test)
print("Accuracy: ", metrics.accuracy_score(target_test, target_pred))

confusion_matrix(target_test, target_pred)
precision = precision_score(target_test, target_pred, average=None)
recall=recall_score(target_test, target_pred, average=None)

print('Precision: {}'.format(precision))
print('Recall: {}'.format(recall))